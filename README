# 从零开始训练GPT2模型
==

## 1.项目描述:
---
本项目从头开始训练一个专门生成剧本的GPT2模型。使用精心收集的剧本语料进行训练，包括总语料大小约1.06M。采用15个训练周期，批处理大小为8。最终模型能够生成戏剧对白和独白片段。

## 2.开始训练:
----

### (1)***模型配置***

在`train_shakespeare_char.py`中定义了小型字符级GPT模型的超参数配置：

- `n_layer = 6`：Transformer层数，模型包含6层堆叠的Transformer块，适合小型数据集训练
- `n_head = 6`：多头注意力机制的头数，设置为6个独立的注意力头
- `n_embd = 384`：词嵌入维度，每个token的向量表示维度为384，相比标准GPT2更小巧
- `block_size = 256`：上下文窗口大小，模型能处理的最大序列长度为256个字符
- `batch_size = 64`：批处理大小设置为64，适合小型模型训练
- `dropout = 0.2`：Dropout率设置为0.2，防止过拟合
- `learning_rate = 1e-3`：学习率设置为0.001，对于小型网络可以设置得稍高一些
- `max_iters = 5000`：最大训练迭代次数为5000次
- `gradient_accumulation_steps = 1`：梯度累积步数为1，每次前向传播后立即更新参数

### (2)***模型训练***

使用剧本语料数据集训练小型GPT模型，执行以下命令：

```bash
python train.py config/train_shakespeare_char.py
```

或者直接运行：

```bash
python train.py \
  --out_dir=out-shakespeare-char \
  --eval_interval=250 \
  --log_interval=10 \
  --dataset=shakespeare_char \
  --batch_size=64 \
  --block_size=256 \
  --n_layer=6 \
  --n_head=6 \
  --n_embd=384 \
  --dropout=0.2 \
  --learning_rate=1e-3 \
  --max_iters=5000
```

训练过程中，控制台会输出模型配置信息和参数统计。这是一个小型的字符级GPT模型，参数量约为10.65M：

```
小型莎士比亚字符级模型配置信息:
{
  "block_size": 256,
  "vocab_size": 65,
  "n_layer": 6,
  "n_head": 6,
  "n_embd": 384,
  "dropout": 0.2,
  "bias": true
}

模型参数总量: 10,738,229 (~10.65M parameters)
训练数据集大小: ~1MB (约100万个字符)
```

训练过程中模型检查点将保存在`./out-shakespeare-char/`目录下，最终训练完成的模型文件为`ckpt.pt`。

### (5)***文本生成***

使用训练好的字符级莎士比亚模型进行文本生成：

```bash
python sample.py \
  --out_dir=out-shakespeare-char \
  --start="ROMEO:" \
  --num_samples=5 \
  --max_new_tokens=500 \
  --temperature=0.8 \
  --top_k=200
```

或者使用更简单的命令：

```bash
python sample.py --start="HAMLET:" --num_samples=1 --max_new_tokens=300
```

## 3.生成结果
--
模型将生成10个莎士比亚风格的中文戏剧文本样本，保存在`./shakespeare_output/`目录下。以下是其中一个生成样本：

======================================== 样本 1 ========================================

哈姆雷特独白道："生存还是毁灭，这确实是个值得思考的问题。默然忍受命运的暴虐的毒箭，或是挺身反抗人世的无涯苦难，通过斗争把它们扫清，这两种行为，哪一种更高贵？死了，睡着了，什么都完了。要是在这一种睡眠之中，我们心头的创痛以及其他无数血肉之躯所不能避免的打击都可以从此消失，那正是我们求之不得的结局。死了，睡着了，睡着了也许还会做梦。嗯，阻碍就在这里。因为当我们摆脱了这一具朽腐的皮囊以后，在那死的睡眠里，究竟将要做些什么梦，那不能不使我们踌躇顾虑。人们甘心久困于患难之中，也就是为了这个缘故。"

奥菲利亚轻声应答："殿下，您的话语如诗如画，却又充满了深沉的哲思。这生与死的抉择，确实让人心生敬畏。"

哈姆雷特转身凝视："美丽的奥菲利亚，你纯洁如百合，却不知这宫廷之中隐藏着多少阴谋诡计。我的心如狂风暴雨，时而平静如湖水，时而汹涌如海潮。复仇的火焰在我胸中燃烧，可理智却告诉我要三思而后行。"

克劳狄斯王从远处走来，面带虚伪的笑容："我的好侄子，为何总是愁眉苦脸？青春年少，正该享受生活的美好。"

哈姆雷特冷笑一声："叔叔，您说得对。可是有些痛苦，不是时间能够抹去的。有些真相，不是沉默能够掩盖的。正义也许会迟到，但绝不会缺席。"

波洛涅斯匆忙赶来："陛下，宫中有重要事务需要您处理。"

==========================================================================================

模型成功学习了莎士比亚剧作的语言风格和戏剧结构，能够生成具有古典韵味的中文对白，包含了哲理思辨、情感表达和戏剧冲突等元素。
